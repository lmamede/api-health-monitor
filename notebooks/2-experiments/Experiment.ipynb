{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YGCJ6Fn9PCKb"
   },
   "source": [
    "# Preparing the environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c51Jo8NhO_Nx"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T01:34:18.968253300Z",
     "start_time": "2026-02-23T01:34:18.956220200Z"
    }
   },
   "source": [
    "#%pip install --upgrade pip\n",
    "#%pip install pandas\n",
    "#%pip install scipy \n",
    "#%pip install scikit-learn \n",
    "#%pip install tqdm \n",
    "#%pip install nbformat\n",
    "#%pip install pyarrow"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 1379,
     "status": "ok",
     "timestamp": 1760974113149,
     "user": {
      "displayName": "Lorena Mamede",
      "userId": "00211236421092021130"
     },
     "user_tz": 180
    },
    "id": "BdL9lh4zO6yJ",
    "ExecuteTime": {
     "end_time": "2026-02-23T01:34:19.008869900Z",
     "start_time": "2026-02-23T01:34:18.969251200Z"
    }
   },
   "source": [
    "# requirements\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import scripts.learner as l\n",
    "import scripts.observer as o\n",
    "import scripts.indicator.calculator as ic\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Experiment"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T01:34:19.061534900Z",
     "start_time": "2026-02-23T01:34:19.013864100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_lambda_series(train_df):\n",
    "    return (\n",
    "        train_df\n",
    "        .sort_values(\"window_id\")\n",
    "        .groupby(\"endpoint\")[\"lam\"]\n",
    "        .expanding()\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "def compute_anomaly_score_series(lambda_series, obs_by_window, train_obs_by_window, window_size, eas):\n",
    "    window_ids = sorted(obs_by_window.keys())\n",
    "    eta_series = []\n",
    "\n",
    "    for window_id in window_ids:\n",
    "        observed = obs_by_window.get(window_id)\n",
    "        if observed is None:\n",
    "            continue\n",
    "\n",
    "        if window_size > 0:\n",
    "            eas.lam = lambda_series.iloc[window_id-1]\n",
    "\n",
    "        out = eas.calculate_eta(\n",
    "            current_window=observed[\"total_requests\"],\n",
    "            seconds_in_window=window_size\n",
    "        )\n",
    "\n",
    "        out[\"lambda\"] = eas.lam\n",
    "        out[\"expected\"] = train_obs_by_window.get(window_id - 1, [])\n",
    "        out[\"window_start\"] = observed[\"window_start\"]\n",
    "        out[\"window_id\"] = window_id\n",
    "        eta_series.append(out)\n",
    "\n",
    "    return pd.DataFrame(eta_series)\n",
    "\n",
    "def compute_ra_series(eta_series, indicators_calculators):\n",
    "    window_ids = sorted(eta_series.keys())\n",
    "\n",
    "    for window_id in window_ids:\n",
    "        for ind in indicators_calculators:\n",
    "            ind.update_ra(eta=eta_series[window_id]['eta'])\n",
    "            ind.record(window_id, eta_series[window_id])\n",
    "    return indicators_calculators\n",
    "\n",
    "def format_window_info(obs_df, train_obs_df):\n",
    "    obs_by_window = {\n",
    "        wid: {\n",
    "            \"total_requests\":g[\"total_requests\"].values,\n",
    "            \"window_start\": g['window_start'].values[0],\n",
    "        }\n",
    "        for wid, g in obs_df.groupby(\"window_id\")\n",
    "    }\n",
    "\n",
    "    train_obs_by_window = {\n",
    "        wid: g[\"total_requests\"].values\n",
    "        for wid, g in train_obs_df.groupby(\"window_id\")\n",
    "    }\n",
    "\n",
    "    return obs_by_window, train_obs_by_window\n",
    "\n",
    "def format_eta_info(df_eta):\n",
    "    eta_by_window = {\n",
    "        wid: {\n",
    "            \"eta\": g[\"eta\"].values[0] if len(g[\"eta\"].values) == 1 else np.nan,\n",
    "            \"window_start\": g[\"window_start\"].values[0] if len(g[\"window_start\"].values) == 1 else np.nan,\n",
    "            \"fDeltap\":g[\"fDeltap\"].values[0] if len(g[\"fDeltap\"].values) == 1 else np.nan,\n",
    "            \"fDp\":g[\"fDp\"].values[0] if len(g[\"fDp\"].values) == 1 else np.nan,\n",
    "            \"fZp\":g[\"fZp\"].values[0] if len(g[\"fZp\"].values) == 1 else np.nan\n",
    "        }\n",
    "        for wid, g in df_eta.groupby(\"window_id\")\n",
    "    }\n",
    "\n",
    "    return eta_by_window\n",
    "\n",
    "def experiment_eta(train_df, obs_df, train_obs_df, window_size):\n",
    "    results_anomaly_detection = []\n",
    "\n",
    "    for endpoint in tqdm(train_df.endpoint.unique()):\n",
    "        lambda_series = compute_lambda_series(train_df[train_df.endpoint == endpoint])\n",
    "\n",
    "        obs_by_window, train_obs_by_window = format_window_info(\n",
    "            obs_df[obs_df.endpoint == endpoint],\n",
    "            train_obs_df[train_obs_df.endpoint == endpoint]\n",
    "        )\n",
    "\n",
    "        eas = o.EndpointAnomalySensor(\n",
    "            endpoint=endpoint,\n",
    "            lam=lambda_series.iloc[0]\n",
    "        )\n",
    "\n",
    "        df_anomaly_score_series = compute_anomaly_score_series(\n",
    "            lambda_series,\n",
    "            obs_by_window,\n",
    "            train_obs_by_window,\n",
    "            window_size,\n",
    "            eas\n",
    "        )\n",
    "\n",
    "        df_anomaly_score_series[\"endpoint\"] = endpoint\n",
    "\n",
    "        results_anomaly_detection.append(df_anomaly_score_series)\n",
    "    return pd.concat(results_anomaly_detection, ignore_index=True)\n",
    "\n",
    "def experiment_ra(train_df, obs_df, train_obs_df, window_size, params):\n",
    "    results = []\n",
    "    for endpoint in tqdm(train_df.endpoint.unique()):\n",
    "        lambda_series = compute_lambda_series(train_df[train_df.endpoint == endpoint])\n",
    "\n",
    "        obs_by_window, train_obs_by_window = format_window_info(\n",
    "            obs_df[obs_df.endpoint == endpoint],\n",
    "            train_obs_df[train_obs_df.endpoint == endpoint]\n",
    "        )\n",
    "\n",
    "        ra_calculators = [\n",
    "            #RaCalculator(endpoint, model=\"sigmoid\", params=params),\n",
    "            #RaCalculator(endpoint, model=\"exponential\", params=params),\n",
    "            #RaCalculator(endpoint, model=\"recovery\", params=params),\n",
    "            ic.RaCalculator(endpoint, model=\"kalman\", params=params),\n",
    "        ]\n",
    "\n",
    "        eas = o.EndpointAnomalySensor(\n",
    "            endpoint=endpoint,\n",
    "            lam=lambda_series.iloc[0]\n",
    "        )\n",
    "\n",
    "        df_anomaly_score_series = compute_anomaly_score_series(\n",
    "            lambda_series,\n",
    "            obs_by_window,\n",
    "            train_obs_by_window,\n",
    "            window_size,\n",
    "            eas\n",
    "        )\n",
    "\n",
    "        eta_series = format_eta_info(df_anomaly_score_series)\n",
    "        indicators_report = compute_ra_series(eta_series, ra_calculators)\n",
    "\n",
    "        for ir in indicators_report:\n",
    "            results.extend(ir.history)\n",
    "\n",
    "    return pd.DataFrame(results)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "id": "8nRoN7lDlarq"
   },
   "cell_type": "markdown",
   "source": "# Evaluation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T01:34:19.071027100Z",
     "start_time": "2026-02-23T01:34:19.063534700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_gt(results_history, window_gt, window_sizes):\n",
    "    \"\"\"\n",
    "        @description Add the corresponding ground truth for each endpoint-window,\n",
    "                     so it can be compared later to generate perfomance metrics\n",
    "    \"\"\"\n",
    "\n",
    "    labeled_data= []\n",
    "    for window_size in window_sizes:\n",
    "        size = int(window_size.replace('s', ''))\n",
    "        labels = window_gt[window_gt['window_size']==size][['endpoint', 'window_id', 'has_anomaly']]\n",
    "        result_df = results_history[results_history['window_size'] == size]\n",
    "        df = pd.merge(result_df, labels, on=['endpoint','window_id'], how='left')\n",
    "        labeled_data.append(df)\n",
    "    return pd.concat(labeled_data, ignore_index=True)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Full Pipeline"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dataset path"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T01:34:19.078318300Z",
     "start_time": "2026-02-23T01:34:19.072022200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ton_iot_train_path = \"../0-datasets/treated_dataset/ton_treated_train.csv\"\n",
    "ton_iot_test_path = \"../0-datasets/treated_dataset/ton_treated_test.csv\""
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Experiment params"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T01:34:19.084082600Z",
     "start_time": "2026-02-23T01:34:19.079305300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "WINDOW_SIZES = ['30s', '60s', '120s','300s']\n",
    "FIXED_WINDOW_SIZE = 120\n",
    "k_VAR = [1., 2., 3., 4., 5.]\n",
    "R_VAR = [0.01,0.05,0.1,0.2]\n",
    "Q_VAR = [0.001,0.005,0.01,0.02]"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Training"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T01:34:20.501530400Z",
     "start_time": "2026-02-23T01:34:19.085080300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tl = l.TrafficLearner(\n",
    "    window_sizes=WINDOW_SIZES,\n",
    "    path_normal_traffic_df=ton_iot_train_path,\n",
    ")\n",
    "\n",
    "normal_traffic_lambda_df = tl.learn_traffic_information()\n",
    "normal_traffic_wind_observations_df = tl.index_windows(tl.get_normal_traffic_df())"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Collecting observations"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T01:34:21.968032800Z",
     "start_time": "2026-02-23T01:34:20.561778900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_ton_test = pd.read_csv(ton_iot_test_path, low_memory=False)\n",
    "df_ton_test['time_local'] = pd.to_datetime(df_ton_test['time_local'])\n",
    "anomalous_traffic_label_df = tl.label_test_windows(df_ton_test.copy())\n",
    "anomalous_traffic_win_observations_df = tl.index_windows(df_ton_test)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T01:34:22.052761300Z",
     "start_time": "2026-02-23T01:34:21.983098100Z"
    }
   },
   "cell_type": "code",
   "source": "anomalous_traffic_win_observations_df.groupby('window_size')['window_id'].count()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "window_size\n",
       "30     939250\n",
       "60     939250\n",
       "120    939250\n",
       "300    939250\n",
       "Name: window_id, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Eta experiments"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T01:34:22.180376300Z",
     "start_time": "2026-02-23T01:34:22.087872100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def window_size_experiment_eta(normal_windows_lambda_df, window_obs, window_normal, window_sizes):\n",
    "    results_eta = []\n",
    "    for window_size in window_sizes:\n",
    "        print(f\"Running experiment: window_size={window_size}\")\n",
    "        size = int(window_size.replace('s', ''))\n",
    "\n",
    "        df_eta = experiment_eta(\n",
    "            normal_windows_lambda_df[normal_windows_lambda_df['window_size'] == size],\n",
    "            window_obs[window_obs['window_size'] == size],\n",
    "            window_normal[window_normal['window_size'] == size],\n",
    "            size,\n",
    "        )\n",
    "\n",
    "        df_eta[\"window_size\"] = size\n",
    "        results_eta.append(df_eta)\n",
    "\n",
    "    return pd.concat(results_eta, ignore_index=True)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T01:34:53.541002800Z",
     "start_time": "2026-02-23T01:34:22.221542800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_eta_results = window_size_experiment_eta(normal_traffic_lambda_df, anomalous_traffic_win_observations_df, normal_traffic_wind_observations_df, window_sizes=WINDOW_SIZES)\n",
    "df_eta_results = add_gt(df_eta_results, anomalous_traffic_label_df, WINDOW_SIZES)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: window_size=30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:15<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: window_size=60s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:08<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: window_size=120s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: window_size=300s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.27it/s]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Ra experiments"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "k variation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T01:36:57.702476900Z",
     "start_time": "2026-02-23T01:34:53.560895400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "k_results=[]\n",
    "for k in k_VAR:\n",
    "    params={\n",
    "        \"beta\": 0.5,\n",
    "        \"k\": k,\n",
    "    }\n",
    "    print(f\"Running experiment: k={k}\")\n",
    "    results = experiment_ra(normal_traffic_lambda_df, anomalous_traffic_win_observations_df, normal_traffic_wind_observations_df, window_size=30, params=params)\n",
    "    results[\"k\"] = k\n",
    "    results[\"window_size\"] = FIXED_WINDOW_SIZE\n",
    "    k_results.append(results)\n",
    "\n",
    "df_k_results = pd.concat(k_results, ignore_index=True)\n",
    "df_k_l_results = add_gt(df_k_results, anomalous_traffic_label_df, WINDOW_SIZES)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: k=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:24<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: k=2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:24<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: k=3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:24<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: k=4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:24<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: k=5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:24<00:00,  2.49s/it]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "q variation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T01:38:38.058562300Z",
     "start_time": "2026-02-23T01:36:57.733710900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "q_results = []\n",
    "for q in Q_VAR:\n",
    "    params={\n",
    "        \"beta\": 0.5,\n",
    "        \"Q\": q,\n",
    "    }\n",
    "    print(f\"Running experiment: Q={q}\")\n",
    "    results = experiment_ra(normal_traffic_lambda_df, anomalous_traffic_win_observations_df, normal_traffic_wind_observations_df, window_size=30, params=params)\n",
    "    results[\"Q\"] = q\n",
    "    results[\"window_size\"] = FIXED_WINDOW_SIZE\n",
    "    q_results.append(results)\n",
    "\n",
    "df_q_results = pd.concat(q_results, ignore_index=True)\n",
    "df_q_l_results = add_gt(df_q_results, anomalous_traffic_label_df, WINDOW_SIZES)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: Q=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:24<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: Q=0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:25<00:00,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: Q=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:25<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: Q=0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:24<00:00,  2.49s/it]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "R variation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T01:40:18.907564100Z",
     "start_time": "2026-02-23T01:38:38.102238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "r_results = []\n",
    "for r in R_VAR:\n",
    "    params={\n",
    "        \"beta\": 0.5,\n",
    "        \"R\": r,\n",
    "    }\n",
    "    print(f\"Running experiment: R={r}\")\n",
    "    results = experiment_ra(normal_traffic_lambda_df, anomalous_traffic_win_observations_df, normal_traffic_wind_observations_df, window_size=30, params=params)\n",
    "    results[\"R\"] = r\n",
    "    results[\"window_size\"] = FIXED_WINDOW_SIZE\n",
    "    r_results.append(results)\n",
    "\n",
    "df_r_results = pd.concat(r_results, ignore_index=True)\n",
    "df_r_l_results = add_gt(df_r_results, anomalous_traffic_label_df, WINDOW_SIZES)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: R=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:24<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: R=0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:25<00:00,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: R=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:25<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: R=0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:25<00:00,  2.51s/it]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Window variation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T01:40:18.968666700Z",
     "start_time": "2026-02-23T01:40:18.960373900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def window_size_experiment_ra(normal_windows_lambda_df, window_obs, window_normal, window_sizes, params):\n",
    "    results_ra = []\n",
    "    for window_size in window_sizes:\n",
    "        print(f\"Running experiment: window_size={window_size}\")\n",
    "        size = int(window_size.replace('s', ''))\n",
    "\n",
    "        df_ra = experiment_ra(\n",
    "            normal_windows_lambda_df[normal_windows_lambda_df['window_size'] == size],\n",
    "            window_obs[window_obs['window_size'] == size],\n",
    "            window_normal[window_normal['window_size'] == size],\n",
    "            window_size=size,\n",
    "            params=params\n",
    "        )\n",
    "\n",
    "        df_ra[\"window_size\"] = size\n",
    "        results_ra.append(df_ra)\n",
    "\n",
    "    return pd.concat(results_ra, ignore_index=True)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T01:41:02.784858700Z",
     "start_time": "2026-02-23T01:40:18.969842900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_ra_win_results = window_size_experiment_ra(normal_traffic_lambda_df, anomalous_traffic_win_observations_df, normal_traffic_wind_observations_df, window_sizes=WINDOW_SIZES, params={})\n",
    "df_ra_win_results = add_gt(df_ra_win_results, anomalous_traffic_label_df, WINDOW_SIZES)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: window_size=30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:22<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: window_size=60s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:11<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: window_size=120s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: window_size=300s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.26it/s]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T01:41:21.148008300Z",
     "start_time": "2026-02-23T01:41:02.842167800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_eta_results.to_csv(\"outputs/kalman_eta_results.csv\", index=False)\n",
    "df_k_l_results.to_csv(\"outputs/kalman_k_results.csv\", index=False)\n",
    "df_q_l_results.to_csv(\"outputs/kalman_q_results.csv\", index=False)\n",
    "df_r_l_results.to_csv(\"outputs/kalman_r_results.csv\", index=False)\n",
    "df_ra_win_results.to_csv(\"outputs/kalman_ra_win_results.csv\", index=False)\n",
    "anomalous_traffic_win_observations_df.to_csv(\"../0-datasets/treated_dataset/anomalous_traffic_win_observations.csv\")"
   ],
   "outputs": [],
   "execution_count": 17
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
